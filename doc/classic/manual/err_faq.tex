\chapter{Common Errors and Questions}

The following explains \INDEX{error messages} and commonly
asked questions.

\section{Why is there no data in my archive?}
The ArchiveEngine should report warning messages whenever the
connection to a channel goes down or when there is a problem with the
data. So after a channel was at least once available, there should be
more or less meaningful messages. After the initial startup, however,
there won't be any information until a channel is at least once
connected. So if a channel never connected, the debugging needs to
fall back to a basic CA error search:\\
Is the data source available?
Can you read the channel with other CA client tools
(probe, EDM, caget, camonitor, ...)?
Can you do that from the computer where you are running
the ArchiveEngine? Does it work with the environment settings and user
ID under which you are trying to run the ArchiveEngine?

\section{Why do I get \#N/A, why are there missing values in my spreadsheet?}
There are several possible reasons for not having any data: There
might not have been any data available because the respective channel
was disconnected or the archive engine was off.  Consequently there is
no \emph{value}, and a spreadsheet might show
\INDEX{'\#N/A'} in the value column. When you look at the
\emph{status} of the channel, those cases might reveal themselves by status
values like ``Disconnected'' or ``Archive Off''.  (The ArchiveExport
tool, Java client and other programs usually have a ``status'' or
``text'' option that you need to use in order to see the status. By
default, you might only see the value).
 
The ArchiveEngine might also have crashed, not getting a chance to
write ``Archive Off''. That would be a likely case if no channel has
data for your time range of interest.  The most common reason for
missing values, however, simply results from the fact that we archive
the original time stamps and you are trying to look at more than one
channel at a time. See the section on time stamp correlation on page~\pageref{sec:timestampcorr}.  

\section{Why do I not get what I think I should get from the network data server?}
I do not know a good way to debug the archive data server when it runs
as a CGI tool. Since it is started by the web server, one cannot easily
attach a debugger to it.
About the only thing that one can check:
\begin{lstlisting}[keywordstyle=\sffamily]
   /tmp/archserver.log
\end{lstlisting}

\noindent Per default, the archive data server will append to the
\INDEX{archserver.log} file whenever run. As a result of a
'get\_values' request, it will log the request and some basic result
information:
\begin{lstlisting}[keywordstyle=\sffamily]
 ---- ArchiveServer Started ----
 archiver.get_values
 how=3, count=10
 get_channel_data
 Start:  03/23/2004 10:47:46.000000000
 End  :  03/23/2004 10:50:57.000000000
 Method: Plot-Binning, 19.1 sec bins
 Open index, key 1 = '../DemoData/index'
 Handling 'fred'
 40 values
 Handling 'janet'
 40 values
 ArchiveServer ran 0.00754285 seconds
\end{lstlisting}

\noindent In case of problems, one can check if the data server received the
correct request. On the machine where the data server is running,
one can then try to reproduce the request with the command-line
ArchiveExport tool.

To disable this data server log file, look for 'LOGFILE' in the data
server sources.

\section{Back in time?} \label{sec:back-in-timefaq} 
The archiver relies on the world going forward in time. When
retrieving samples from an archive, we expect the time stamps to be
monotonic and non-decreasing. Time stamps going \INDEX{back in time} break the
lookup mechanism. Data files with non-monotonic time stamps are
useless. Unfortunately, the clocks of IOCs or other computers running
CA servers can be mis-configured. The ArchiveEngine attempts to catch
some of these problems, but all it can do is drop the affected
samples, there is no recipe for correcting the time stamps.

Bottom line: You need to have the clocks of all CA servers properly configured
(also see page~\pageref{back:in:time}).
There are other reasons for back-in-time warnings that have no good
solution:
\begin{itemize}
\item When a channel disconnects or when the ArchiveEngine is shut
  down, the engine will add ``Disconnected'' or ``Archive Off'' values
  to the archive. Those values will carry the current value of the
  host's clock, the current time stamp of the computer that is running
  the engine. The host's clock is rarely perfectly synchronized with
  the IOC's clocks, so if we had just received a sample from the IOC
  and the host's clock is only a little late, we'll get a ``back in
  time'' warning.

  To resolve this, the engine will tweak the time of the
  ``Disconnected'' or ``Archive Off'' values so that they're stamped
  just after the last sample in the archive.

\item When a channel gets disabled, it really gets disabled because
  \emph{another} channel in its group, one that was configured as
  ``disabling'', turned true and thus disabled the whole group.
  The engine writes a ``Disabled'' value for each disabled channel,
  and as a time stamp it uses the time stamp of the channel that
  caused the disable.
  This will later help you to see exactly when channels were disabled
  and why because the disabling and the disabled channels will all
  have the same time stamp.

  A problem arises especially when the disabling channel is from a
  different IOC. Assume we just received samples for several channels
  and added them to the archive, and then some split seconds later the
  value of the disabling channel arrives, delayed by the network. That
  disabling time stamp might be a little older than the stamps of the
  values that we already wrote, so the attempt to add a ``Disabled''
  value results in back-in-time warnings (which again get resolved by
  hacking the time stamps).

\item Some channels seldom change. Examples include ``Setpoint''
  channels which are only modified by operator input. They might stay
  the same for days or weeks.
  When an ArchiveEngine stops, it will add an ``Archive Off''
  event. When it is then re-started, it will receive the current
  value of a channel, which might older than the
  ``Archive Off'' event. So the current value causes a back-in-time
  situation, again resolved by using the last time stamp in the
  archive instead of the original stamp of the sample.
\end{itemize}

\noindent In summary, most back-in-time warnings can be ignored as long as the
clocks of the hosts and IOCs are reasonably in sync.

\section{Found an existing lock file '\INDEX{archive\_active.lck}'}
When the ArchiveEngine is started, it creates a \INDEX{lock file} in
the current directory. The lock file is an ordinary text file
that contains the start time when the engine was launched. When
the engine stops, it removes the file.

The idea here is to prevent more than one archive engine to run
in the same directory, writing to the same index and data files
and thus creating garbage data: Whenever the archive engine sees
a lock file, it refuses to run with the above error message.

Under normal circumstances, one should not find such lock files
left behind after the engine shuts down cleanly. The presence of
a lock file indicates two possible problems:
\begin{enumerate}
\item[a)] There is in fact already an archive engine running in
this directory, so you cannot start another one.
\item[b)] The previous engine crashed, it was stopped without
opportunity to close the data files and remove the lock file.
It \emph{might} be OK to simply remove the lock file and try
again, but since the crash could have damaged the data files, it
is advisable to back them up and run a test before removing the
lock file and starting another engine.
\end{enumerate}

\section{Crashes of the ArchiveEngine, ...} \label{sec:crash} 
Though some care was taken in testing the ArchiveEngine, several
problems will remain. Before you go all the way to implement a better
if not perfect ArchiveEngine or other piece of the ChannelArchiver
yourself, you might want to see if you can reproduce the crash and
aid in debugging it.

Under Linux, this usually means: Allow the generation of ``core'' files
and investigate them. With recent Linux distributions, add ``set
ulimit -c unlimited'' to your login-script. When the ArchiveEngine
crashes, it should now generate a core dump, often called
``core.$<$PID$>$'', using the process ID of the crashed process. Then use
``gdb'' to locate the area of code that caused the crash:

\begin{lstlisting}[keywordstyle=\sffamily]
    cd /where/the/core/file/is
    gdb /full/path/to/ArchiveEngine core.12345
    # Generate a stack trace
    bt
    # You should see a stack trace leading up
    # to the crash, something like
    # 0   write(....)
    # 1   printf(....)
    # 2   MsgLogger(..)
    # 3   ArchiveChannel::handle_value(...
    # 4   ...

    # Now you can select some stack frames and see
    # what is happening in there
    frame 3
    list
    # ... shows the code in
    #      ArchiveChannel::handle_value(..
    # that leads up to the crash
    quit
\end{lstlisting}

\noindent Please email the result so that we can try to eliminate the
problem.

\section{Cannot create a new data file within \INDEX{file size limit}}
You specified a rather small file size limit (file\_size option in the
ArchiveEngine configuration), and the currently required buffer size
for a single channel already exceeds that file size limit.
The Engine will actually go ahead and create a bigger file in the hope
that this avoids data loss.

One example that could cause this: You try to archive array channels,
where each individual sample is already quite big, and picked a tiny
file\_size. 

\section{Found an existing '\INDEX{indextool\_active.lck}' lock file}
When an ArchiveIndexTool is started, it creates a lock file
similar to the ArchiveEngine, in the hope of preventing more than
one Index Tool from modifying a master index at the same time.
See preceding description of archiver\_active.lck file.

\section{What is a ``\INDEX{regular expression}''?}
See a book on perl or the manual page for ``grep'' for details.
The following table compares the regular expression syntax with the simpler
file name wildcards. Most regular expressions don't have a wildcard equivalent.

\begin{center}
\begin{tabular}{l|l|l}
Reg.\ Exp.    &   Wildcard  &   Matches...  \\
\hline 
.             &   ?         &   any single character \\
.*            &   *         &   any string with 0 or more characters \\
.+            &             &   any string with 1 or more characters \\
\verb!^!      &             &   start of string \\
\$            &             &   end of string \\
\verb![aA]!   &             &   'a' or 'A' \\
\verb![0-9]!  &             &   any single digit \\
\verb![0-9]+! &             &   '0' or '1234' or ... \\
\verb!^!abc\$ &   abc       &   'abc' \\
b             &   *b*       &   'abc' or 'bbb' or 'xby' or ... \\
\end{tabular}
\end{center}

\section{What about using \INDEX{NFS}?}
For the network data server, it's probably OK to place some of the actual data
on volumes that are NFS-mounted and not local to the data server.
For the archive engine, use of NFS is discouraged.

For one, the performance of NFS is usually by orders of magnitude below
the performance of locally mounted disk drives.
In addition, NFS mounted disk drives can always have unexpected errors
as a result of network delays or outages.
The API for writing files, that means the read, write, and seek calls offered
by the operating system, does not offer a clear indication if an error
was a disk error or a network error, because NFS was specifically designed
to look like a local file system, which it's clearly not.
So the detection of NFS errors is difficult. And even if the engine wanted
to handle those NFS errors which are to be expected, should it simply stop
for 10 minutes, then try again? What if such an error happens in the middle
of a write cycle, where partial data was written, and the archive files are
in an inconsistent state?
So as long as these issues are not properly addressed, the use of NFS with
archive engines is strongly discouraged.

\section{What is a \INDEX{shallow index}?}
An experimental feature under development:
While a 'full' master index references the data blocks in data files,
a 'shallow' index only points to yet another index file.
When building a hierarchy of indices, shallow indices for the summary
indices are much smaller than their full counterpart,
so they update quicker.
For big data sets, where a 'full' index grows beyond 2GB, a shallow
index is also the best option.
